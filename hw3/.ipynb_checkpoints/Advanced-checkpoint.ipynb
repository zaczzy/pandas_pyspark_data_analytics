{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced: Text Processing in Matrices\n",
    "\n",
    "## Load Natural Language Toolkit for Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /opt/conda/lib/python3.5/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install nltk\n",
    "import nltk\n",
    "\n",
    "# Enter 'd' for Download, then 'punkt', and then 'q' for quit\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import text files into dictionary\n",
    "\n",
    "As a \"corpus\" we fetched some data from Wikipedia, based on currently\n",
    "trendy (2/18/2017) topics.  Each topic had multiple interpretations, some of which \n",
    "we suspected would \"intersect\" in interesting ways (e.g., Trump/Putin, Cloud/Google, \n",
    "Cloud/Climate).  Others had various interpretations (e.g., there are many types of \n",
    "Football).  See _Wikipedia.ipynb_ for the original download code.\n",
    "\n",
    "Selected topics (for which the top-10 matches were returned by Wikipedia) were:\n",
    "\n",
    " * Pennsylvania\n",
    " * Trump\n",
    " * Apple\n",
    " * Google\n",
    " * Farm\n",
    " * Climate\n",
    " * Cloud\n",
    " * Football\n",
    " * Government\n",
    " * Putin\n",
    "\n",
    "*docs* is a map from file --> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Province of Pennsylvania.txt\n",
      "Loaded Eric Trump.txt\n",
      "Loaded Apple.txt\n",
      "Loaded Putin khuilo!.txt\n",
      "Loaded Cooking apple.txt\n",
      "Loaded Apple TV.txt\n",
      "Loaded Pennsylvania Historical and Museum Commission.txt\n",
      "Loaded Football player.txt\n",
      "Loaded Donald Trump.txt\n",
      "Loaded Public image of Vladimir Putin.txt\n",
      "Loaded Google Developers.txt\n",
      "Loaded Alpine climate.txt\n",
      "Loaded Desert climate.txt\n",
      "Loaded Century Farm.txt\n",
      "Loaded Apple Inc..txt\n",
      "Loaded Animal Farm.txt\n",
      "Loaded Google Books.txt\n",
      "Loaded Google Account.txt\n",
      "Loaded Oort cloud.txt\n",
      "Loaded HP Cloud.txt\n",
      "Loaded Farm Aid.txt\n",
      "Loaded History of Pennsylvania.txt\n",
      "Loaded E-government.txt\n",
      "Loaded Trump University.txt\n",
      "Loaded Outline of Pennsylvania.txt\n",
      "Loaded Google Search.txt\n",
      "Loaded Arrest of Vladimir Putin viral video.txt\n",
      "Loaded AtGoogleTalks.txt\n",
      "Loaded Cloud computing.txt\n",
      "Loaded Government of Australia.txt\n",
      "Loaded Government.txt\n",
      "Loaded Family of Donald Trump.txt\n",
      "Loaded Stratus cloud.txt\n",
      "Loaded Brook Farm.txt\n",
      "Loaded Google.txt\n",
      "Loaded Wind farm.txt\n",
      "Loaded Subarctic climate.txt\n",
      "Loaded Google Videos.txt\n",
      "Loaded Geography of Pennsylvania.txt\n",
      "Loaded Mediterranean climate.txt\n",
      "Loaded United States farm bill.txt\n",
      "Loaded Local government.txt\n",
      "Loaded Football.txt\n",
      "Loaded Crimean speech of Vladimir Putin.txt\n",
      "Loaded College football.txt\n",
      "Loaded Climate change.txt\n",
      "Loaded State Farm Insurance.txt\n",
      "Loaded Township (Pennsylvania).txt\n",
      "Loaded Climate justice.txt\n",
      "Loaded Pennsylvania Regions.txt\n",
      "Loaded CLOUD experiment.txt\n",
      "Loaded Apple II series.txt\n",
      "Loaded Government of the United Kingdom.txt\n",
      "Loaded Government in exile.txt\n",
      "Loaded Mushroom cloud.txt\n",
      "Loaded Google Talk.txt\n",
      "Loaded Head of government.txt\n",
      "Loaded Melania Trump.txt\n",
      "Loaded Google+.txt\n",
      "Loaded Australian rules football.txt\n",
      "Loaded Cloud.txt\n",
      "Loaded Russia under Vladimir Putin.txt\n",
      "Loaded Tag cloud.txt\n",
      "Loaded Apple Corps.txt\n",
      "Loaded Flag football.txt\n",
      "Loaded Putin. War.txt\n",
      "Loaded Apple I.txt\n",
      "Loaded Government agency.txt\n",
      "Loaded Happy Birthday, Mr. Putin!.txt\n",
      "Loaded Pennsylvania Dutch.txt\n",
      "Loaded Forms of government.txt\n",
      "Loaded Foreign policy of Vladimir Putin.txt\n",
      "Loaded Pro Football Hall of Fame.txt\n",
      "Loaded Pennsylvania.txt\n",
      "Loaded Oceanic climate.txt\n",
      "Loaded Trump fragrances.txt\n",
      "Loaded Calumet Farm.txt\n",
      "Loaded Association football.txt\n",
      "Loaded Home Farm F.C..txt\n",
      "Loaded Football team.txt\n",
      "Loaded Climate model.txt\n",
      "Loaded The Trump Organization.txt\n",
      "Loaded Farm.txt\n",
      "Loaded Putin Must Go.txt\n",
      "Loaded Government of Malaysia.txt\n",
      "Loaded Vladimir Putin.txt\n",
      "Loaded Apple Store.txt\n",
      "Loaded Climate.txt\n",
      "Loaded American football.txt\n",
      "Loaded Apple III.txt\n",
      "Loaded Cumulus cloud.txt\n",
      "Loaded Arcus cloud.txt\n",
      "Loaded Trump family.txt\n",
      "Loaded Football in England.txt\n",
      "Loaded Climate classification.txt\n",
      "Loaded Google Hangouts.txt\n",
      "Loaded Pennsylvania Railroad.txt\n",
      "Loaded Legal affairs of Donald Trump.txt\n",
      "All files loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "docs = {}\n",
    "\n",
    "for filename in os.listdir('text'):\n",
    "    file = open('text/' + filename)\n",
    "    docs[filename] = file.read()\n",
    "    print ('Loaded',filename)\n",
    "\n",
    "print (\"All files loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Other preliminaries to get you started.\n",
    "\n",
    "The function *has_letter* should be used to filter words based on the presence of a letter.\n",
    "\n",
    "The set *stopwords* includes words to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "# Returns True if the input (string) parameter has\n",
    "# any sort of letter in it, else returns False.\n",
    "\"\"\"\n",
    "def has_letter(x):\n",
    "    return re.match('.*[a-zA-Z].*',x) != None\n",
    "\n",
    "# Stopwords are words we will ignore for search\n",
    "# purposes, because they are too common to be useful\n",
    "stopwords = set()\n",
    "\n",
    "stop_file = open('stopwords.txt')\n",
    "for line in stop_file:\n",
    "    stopwords.add(line.strip())\n",
    "\n",
    "# The NLTK parser breaks apostrophe-s into a separate \"word\"\n",
    "# so we'll want to add it to the list... Though it's technically\n",
    "# not a stop word in the traditional sense.\n",
    "stopwords.add(\"'s\")\n",
    "\n",
    "# Use this as the maximum number of words we will index\n",
    "MAX_WORDS = 18174\n",
    "\n",
    "# Create the word stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Your Code Goes Here!\n",
    "\n",
    "Note that you may want to read more about TF*IDF scoring at:\n",
    "\n",
    "* http://nlp.stanford.edu/IR-book/html/htmledition/term-frequency-and-weighting-1.html\n",
    "* https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wind farm is a gro'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['Wind farm.txt'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lexicon = {}\n",
    "inverse_lexicon = []\n",
    "word_count = 0\n",
    "doc_vectors = np.zeros((len(docs), MAX_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def doc_vector(content, vector, lexicon, inverse_lexicon, stopwords, word_count):\n",
    "    tokens = nltk.word_tokenize(content)\n",
    "    for token in tokens:\n",
    "        if(has_letter(token) and token not in stopwords):\n",
    "            stem_token = stemmer.stem(token)\n",
    "            if (stem_token in lexicon):\n",
    "                vector[lexicon[stem_token]] += 1\n",
    "            else:\n",
    "                if(word_count < MAX_WORDS):\n",
    "                    lexicon[stem_token] = word_count\n",
    "                    inverse_lexicon.append(stem_token)\n",
    "                    vector[word_count] += 1\n",
    "                    word_count += 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# doc_vector(docs['Farm.txt'], doc_vectors[0], lexicon, inverse_lexicon, stopwords, 0)\n",
    "i = 0\n",
    "for doc in docs:\n",
    "    word_count = doc_vector(docs[doc], doc_vectors[i], lexicon, inverse_lexicon, stopwords, word_count)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n",
      "2249\n",
      "1272\n",
      "219\n",
      "360\n",
      "508\n",
      "1998\n",
      "157\n",
      "1135\n",
      "586\n",
      "188\n",
      "154\n",
      "1053\n",
      "1553\n",
      "220\n",
      "284\n",
      "1289\n",
      "1132\n",
      "882\n",
      "526\n",
      "667\n",
      "819\n",
      "548\n",
      "305\n",
      "1351\n",
      "1483\n",
      "194\n",
      "304\n",
      "490\n",
      "529\n",
      "1469\n",
      "581\n",
      "633\n",
      "1535\n",
      "408\n",
      "114\n",
      "323\n",
      "1253\n",
      "1216\n",
      "1215\n",
      "110\n",
      "87\n",
      "2509\n",
      "400\n",
      "704\n",
      "642\n",
      "587\n",
      "1896\n",
      "467\n",
      "981\n",
      "72\n",
      "479\n",
      "502\n",
      "511\n",
      "406\n",
      "1393\n",
      "633\n",
      "827\n",
      "37\n",
      "399\n",
      "1641\n",
      "213\n",
      "272\n",
      "317\n",
      "382\n",
      "1991\n",
      "1591\n",
      "232\n",
      "108\n",
      "1040\n",
      "509\n",
      "1739\n",
      "399\n",
      "1992\n",
      "359\n",
      "594\n",
      "1394\n",
      "717\n",
      "662\n",
      "511\n",
      "2347\n",
      "349\n",
      "531\n",
      "573\n",
      "961\n",
      "213\n",
      "1326\n",
      "530\n",
      "1276\n",
      "1238\n",
      "376\n",
      "1585\n",
      "297\n",
      "393\n",
      "959\n",
      "317\n",
      "314\n",
      "302\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc_vectors)):\n",
    "    print(len([x for x in doc_vectors[i] if x != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.,  16.,  13.,   1.,   0.,   0.,  15.,   2.,  14.,   3.,   7.,\n",
       "         0.,   9.,  19.,   1.,   1.,   6.,  13.,   4.,   0.,   2.,   5.,\n",
       "         3.,   2.,   7.,  15.,   0.,   0.,   5.,   1.,  13.,   6.,   5.,\n",
       "         4.,   6.,   0.,   0.,  10.,   3.,  11.,   1.,   2.,  12.,   3.,\n",
       "        19.,   2.,   1.,   2.,   0.,   9.,   1.,   4.,   2.,   4.,   1.,\n",
       "        14.,   3.,   7.,   1.,   2.,   8.,   4.,   2.,   0.,   7.,   9.,\n",
       "        20.,   0.,   1.,  16.,   1.,  11.,   0.,   4.,   1.,   2.,  10.,\n",
       "         4.,   6.,   1.,  15.,   1.,   3.,   1.,   1.,   0.,   8.,   1.,\n",
       "        18.,  18.,   7.,   9.,   0.,   2.,   8.,   1.,   3.,   4.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus_size = len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import log10\n",
    "idfs = [log10(corpus_size / np.count_nonzero(doc_vectors[:,i])) for i in range(MAX_WORDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_query_vector(query):\n",
    "    query_vector = np.zeros(MAX_WORDS)\n",
    "    global word_count\n",
    "    word_count = doc_vector(query, query_vector, lexicon, inverse_lexicon, stopwords, word_count)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search(vectors, idf, query, num_results):\n",
    "    query_idf = idf * query\n",
    "    \n",
    "    scores = np.array([(vectors[i] * idf) @ query_idf / (np.linalg.norm(vectors[i] * idf) * np.linalg.norm(query_idf))\n",
    "                       for i in range(corpus_size)])\n",
    "    dict = {\"docid\":np.arange(corpus_size), \"docname\":np.array(list(docs.keys())), \"score\":pd.to_numeric(scores, errors='coerce')}\n",
    "    result = pd.DataFrame.from_dict(dict)\n",
    "    result = result.sort_values(\"score\", ascending=False)\n",
    "    return result[0:10]\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>docname</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>Apple Inc..txt</td>\n",
       "      <td>0.488850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Apple I.txt</td>\n",
       "      <td>0.433946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Apple III.txt</td>\n",
       "      <td>0.400616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>Apple II series.txt</td>\n",
       "      <td>0.349057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>Apple Store.txt</td>\n",
       "      <td>0.336980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Apple.txt</td>\n",
       "      <td>0.329733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Cooking apple.txt</td>\n",
       "      <td>0.303956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Apple TV.txt</td>\n",
       "      <td>0.301958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Apple Corps.txt</td>\n",
       "      <td>0.274117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Home Farm F.C..txt</td>\n",
       "      <td>0.019623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid              docname     score\n",
       "80     80       Apple Inc..txt  0.488850\n",
       "31     31          Apple I.txt  0.433946\n",
       "20     20        Apple III.txt  0.400616\n",
       "60     60  Apple II series.txt  0.349057\n",
       "84     84      Apple Store.txt  0.336980\n",
       "37     37            Apple.txt  0.329733\n",
       "7       7    Cooking apple.txt  0.303956\n",
       "17     17         Apple TV.txt  0.301958\n",
       "24     24      Apple Corps.txt  0.274117\n",
       "48     48   Home Farm F.C..txt  0.019623"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(doc_vectors, idfs, create_query_vector(\"Apple Steve jobs\"), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>docname</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Donald Trump.txt</td>\n",
       "      <td>0.660205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>Legal affairs of Donald Trump.txt</td>\n",
       "      <td>0.635921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>The Trump Organization.txt</td>\n",
       "      <td>0.627659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Trump University.txt</td>\n",
       "      <td>0.592956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>Public image of Vladimir Putin.txt</td>\n",
       "      <td>0.590706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>Family of Donald Trump.txt</td>\n",
       "      <td>0.583825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vladimir Putin.txt</td>\n",
       "      <td>0.575655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>Trump family.txt</td>\n",
       "      <td>0.523255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>Eric Trump.txt</td>\n",
       "      <td>0.485600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>Russia under Vladimir Putin.txt</td>\n",
       "      <td>0.461298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid                             docname     score\n",
       "42     42                    Donald Trump.txt  0.660205\n",
       "91     91   Legal affairs of Donald Trump.txt  0.635921\n",
       "89     89          The Trump Organization.txt  0.627659\n",
       "77     77                Trump University.txt  0.592956\n",
       "69     69  Public image of Vladimir Putin.txt  0.590706\n",
       "72     72          Family of Donald Trump.txt  0.583825\n",
       "1       1                  Vladimir Putin.txt  0.575655\n",
       "74     74                    Trump family.txt  0.523255\n",
       "59     59                      Eric Trump.txt  0.485600\n",
       "65     65     Russia under Vladimir Putin.txt  0.461298"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(doc_vectors, idfs, create_query_vector(\"Trump Putin\"), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>docname</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Google.txt</td>\n",
       "      <td>0.654294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Google Developers.txt</td>\n",
       "      <td>0.549571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>Google Account.txt</td>\n",
       "      <td>0.518488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>Google Talk.txt</td>\n",
       "      <td>0.486282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Cloud computing.txt</td>\n",
       "      <td>0.484473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Arcus cloud.txt</td>\n",
       "      <td>0.454484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Google Books.txt</td>\n",
       "      <td>0.450616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Cloud.txt</td>\n",
       "      <td>0.439715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AtGoogleTalks.txt</td>\n",
       "      <td>0.431917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>Stratus cloud.txt</td>\n",
       "      <td>0.424013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid                docname     score\n",
       "47     47             Google.txt  0.654294\n",
       "96     96  Google Developers.txt  0.549571\n",
       "61     61     Google Account.txt  0.518488\n",
       "82     82        Google Talk.txt  0.486282\n",
       "2       2    Cloud computing.txt  0.484473\n",
       "10     10        Arcus cloud.txt  0.454484\n",
       "12     12       Google Books.txt  0.450616\n",
       "25     25              Cloud.txt  0.439715\n",
       "3       3      AtGoogleTalks.txt  0.431917\n",
       "64     64      Stratus cloud.txt  0.424013"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(doc_vectors, idfs, create_query_vector(\"Google Cloud\"), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
