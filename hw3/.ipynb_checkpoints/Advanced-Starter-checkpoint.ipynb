{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced: Text Processing in Matrices\n",
    "\n",
    "## Load Natural Language Toolkit for Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.2.2.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): six in /opt/conda/lib/python3.5/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/42/b5/27/718985cd9719e8a44a405d264d98214c7a607fb65f3a006f28\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.2\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> punkt\n",
      "    Downloading package punkt to /home/jovyan/nltk_data...\n",
      "      Unzipping tokenizers/punkt.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install nltk\n",
    "import nltk\n",
    "\n",
    "# Enter 'd' for Download, then 'punkt', and then 'q' for quit\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import text files into dictionary\n",
    "\n",
    "As a \"corpus\" we fetched some data from Wikipedia, based on currently\n",
    "trendy (2/18/2017) topics.  Each topic had multiple interpretations, some of which \n",
    "we suspected would \"intersect\" in interesting ways (e.g., Trump/Putin, Cloud/Google, \n",
    "Cloud/Climate).  Others had various interpretations (e.g., there are many types of \n",
    "Football).  See _Wikipedia.ipynb_ for the original download code.\n",
    "\n",
    "Selected topics (for which the top-10 matches were returned by Wikipedia) were:\n",
    "\n",
    " * Pennsylvania\n",
    " * Trump\n",
    " * Apple\n",
    " * Google\n",
    " * Farm\n",
    " * Climate\n",
    " * Cloud\n",
    " * Football\n",
    " * Government\n",
    " * Putin\n",
    "\n",
    "*docs* is a map from file --> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Province of Pennsylvania.txt\n",
      "Loaded Eric Trump.txt\n",
      "Loaded Apple.txt\n",
      "Loaded Putin khuilo!.txt\n",
      "Loaded Cooking apple.txt\n",
      "Loaded Apple TV.txt\n",
      "Loaded Pennsylvania Historical and Museum Commission.txt\n",
      "Loaded Football player.txt\n",
      "Loaded Donald Trump.txt\n",
      "Loaded Public image of Vladimir Putin.txt\n",
      "Loaded Google Developers.txt\n",
      "Loaded Alpine climate.txt\n",
      "Loaded Desert climate.txt\n",
      "Loaded Century Farm.txt\n",
      "Loaded Apple Inc..txt\n",
      "Loaded Animal Farm.txt\n",
      "Loaded Google Books.txt\n",
      "Loaded Google Account.txt\n",
      "Loaded Oort cloud.txt\n",
      "Loaded HP Cloud.txt\n",
      "Loaded Farm Aid.txt\n",
      "Loaded History of Pennsylvania.txt\n",
      "Loaded E-government.txt\n",
      "Loaded Trump University.txt\n",
      "Loaded Outline of Pennsylvania.txt\n",
      "Loaded Google Search.txt\n",
      "Loaded Arrest of Vladimir Putin viral video.txt\n",
      "Loaded AtGoogleTalks.txt\n",
      "Loaded Cloud computing.txt\n",
      "Loaded Government of Australia.txt\n",
      "Loaded Government.txt\n",
      "Loaded Family of Donald Trump.txt\n",
      "Loaded Stratus cloud.txt\n",
      "Loaded Brook Farm.txt\n",
      "Loaded Google.txt\n",
      "Loaded Wind farm.txt\n",
      "Loaded Subarctic climate.txt\n",
      "Loaded Google Videos.txt\n",
      "Loaded Geography of Pennsylvania.txt\n",
      "Loaded Mediterranean climate.txt\n",
      "Loaded United States farm bill.txt\n",
      "Loaded Local government.txt\n",
      "Loaded Football.txt\n",
      "Loaded Crimean speech of Vladimir Putin.txt\n",
      "Loaded College football.txt\n",
      "Loaded Climate change.txt\n",
      "Loaded State Farm Insurance.txt\n",
      "Loaded Township (Pennsylvania).txt\n",
      "Loaded Climate justice.txt\n",
      "Loaded Pennsylvania Regions.txt\n",
      "Loaded CLOUD experiment.txt\n",
      "Loaded Apple II series.txt\n",
      "Loaded Government of the United Kingdom.txt\n",
      "Loaded Government in exile.txt\n",
      "Loaded Mushroom cloud.txt\n",
      "Loaded Google Talk.txt\n",
      "Loaded Head of government.txt\n",
      "Loaded Melania Trump.txt\n",
      "Loaded Google+.txt\n",
      "Loaded Australian rules football.txt\n",
      "Loaded Cloud.txt\n",
      "Loaded Russia under Vladimir Putin.txt\n",
      "Loaded Tag cloud.txt\n",
      "Loaded Apple Corps.txt\n",
      "Loaded Flag football.txt\n",
      "Loaded Putin. War.txt\n",
      "Loaded Apple I.txt\n",
      "Loaded Government agency.txt\n",
      "Loaded Happy Birthday, Mr. Putin!.txt\n",
      "Loaded Pennsylvania Dutch.txt\n",
      "Loaded Forms of government.txt\n",
      "Loaded Foreign policy of Vladimir Putin.txt\n",
      "Loaded Pro Football Hall of Fame.txt\n",
      "Loaded Pennsylvania.txt\n",
      "Loaded Oceanic climate.txt\n",
      "Loaded Trump fragrances.txt\n",
      "Loaded Calumet Farm.txt\n",
      "Loaded Association football.txt\n",
      "Loaded Home Farm F.C..txt\n",
      "Loaded Football team.txt\n",
      "Loaded Climate model.txt\n",
      "Loaded The Trump Organization.txt\n",
      "Loaded Farm.txt\n",
      "Loaded Putin Must Go.txt\n",
      "Loaded Government of Malaysia.txt\n",
      "Loaded Vladimir Putin.txt\n",
      "Loaded Apple Store.txt\n",
      "Loaded Climate.txt\n",
      "Loaded American football.txt\n",
      "Loaded Apple III.txt\n",
      "Loaded Cumulus cloud.txt\n",
      "Loaded Arcus cloud.txt\n",
      "Loaded Trump family.txt\n",
      "Loaded Football in England.txt\n",
      "Loaded Climate classification.txt\n",
      "Loaded Google Hangouts.txt\n",
      "Loaded Pennsylvania Railroad.txt\n",
      "Loaded Legal affairs of Donald Trump.txt\n",
      "All files loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "docs = {}\n",
    "\n",
    "for filename in os.listdir('text'):\n",
    "    file = open('text/' + filename)\n",
    "    docs[filename] = file.read()\n",
    "    print ('Loaded',filename)\n",
    "\n",
    "print (\"All files loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Other preliminaries to get you started.\n",
    "\n",
    "The function *has_letter* should be used to filter words based on the presence of a letter.\n",
    "\n",
    "The set *stopwords* includes words to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "# Returns True if the input (string) parameter has\n",
    "# any sort of letter in it, else returns False.\n",
    "\"\"\"\n",
    "def has_letter(x):\n",
    "    return re.match('.*[a-zA-Z].*',x) != None\n",
    "\n",
    "# Stopwords are words we will ignore for search\n",
    "# purposes, because they are too common to be useful\n",
    "stopwords = set()\n",
    "\n",
    "stop_file = open('stopwords.txt')\n",
    "for line in stop_file:\n",
    "    stopwords.add(line.strip())\n",
    "\n",
    "# The NLTK parser breaks apostrophe-s into a separate \"word\"\n",
    "# so we'll want to add it to the list... Though it's technically\n",
    "# not a stop word in the traditional sense.\n",
    "stopwords.add(\"'s\")\n",
    "\n",
    "# Use this as the maximum number of words we will index\n",
    "MAX_WORDS = 18174\n",
    "\n",
    "# Create the word stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Your Code Goes Here!\n",
    "\n",
    "Note that you may want to read more about TF*IDF scoring at:\n",
    "\n",
    "* http://nlp.stanford.edu/IR-book/html/htmledition/term-frequency-and-weighting-1.html\n",
    "* https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
